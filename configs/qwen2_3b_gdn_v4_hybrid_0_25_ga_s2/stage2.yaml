data:
  cache_dir: '/workspace/checkpoints/data_cache/chunked_context4096'
teacher_model:
  name: fla-hub/Qwen2.5-3B-Instruct
student_model:
  name: gdn_v4
  keep_full_attention_layers:
  #- 20
  #- 32
  #- 33
  #- 21
  #- 22
  #- 25
  #- 17
  #- 19
  #- 5
  - 20
  - 5
  - 33
  - 17
  - 22
  - 32
  - 13
  - 21
  - 27
train:
  target_tokens: 600000000
  batch_size: 32
  micro_batch_size: 2
  train_seq_len: 4096
  lr_scheduler_type: constant
  lr: 7.0e-06
  lr_attn: 0.0001
  max_grad_norm: 1.0
  output_dir: '/workspace/checkpoints/outputs/qwen2_3b_gdn_v4_hybrid_0_25_swa/stage2'
  student_init_ckpt: '/workspace/checkpoints/outputs/qwen2_3b_gdn_v4_hybrid_0_125_uniform/stage1/converted-hf'
  max_length: 4096
  add_eos_token: false
  resume_from_checkpoint: None
stage: 2
